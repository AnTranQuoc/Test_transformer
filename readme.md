# Hand Gesture Recognition with TransformerEncoder

Nháº­n diá»‡n cá»­ chá»‰ tay thá»i gian thá»±c tá»« dá»¯ liá»‡u keypoints Ä‘Æ°á»£c trÃ­ch xuáº¥t báº±ng **MediaPipe**, sá»­ dá»¥ng mÃ´ hÃ¬nh **TransformerEncoder** Ä‘á»ƒ phÃ¢n loáº¡i cÃ¡c cá»­ chá»‰ sau:

- ğŸ‘Œ OK
- âœŠ Náº¯m Ä‘áº¥m
- ğŸ– XÃ²e tay
- â˜ 1 ngÃ³n
- âœŒ 2 ngÃ³n
- ğŸ¤Ÿ 3 ngÃ³n
- ğŸ–– 4 ngÃ³n
- ğŸ–• Cá»­ chá»‰ báº­y báº¡

---

## ğŸ¥ Video Demo
[![Watch the demo](demo_thumbnail.png)](demo_video.mp4)  
*Báº¥m vÃ o hÃ¬nh Ä‘á»ƒ xem video demo káº¿t quáº£ cháº¡y mÃ´ hÃ¬nh.*

---

## Data Sá»­ Dá»¥ng
Nguá»“n: Dá»¯ liá»‡u keypoints Ä‘Æ°á»£c thu tháº­p báº±ng MediaPipe Hands.
Äá»‹nh dáº¡ng: Má»—i máº«u lÃ  máº£ng (21, 3) gá»“m tá»a Ä‘á»™ (x, y, z) cá»§a 21 landmarks trÃªn bÃ n tay.
Tiá»n xá»­ lÃ½:
Chuáº©n hÃ³a vá»‹ trÃ­ (dá»‹ch Ä‘á»ƒ cá»• tay vá» gá»‘c tá»a Ä‘á»™).
Scale kÃ­ch thÆ°á»›c bÃ n tay vá» cÃ¹ng tá»· lá»‡.
Sá»‘ lá»›p: 8 lá»›p cá»­ chá»‰ (OK, Náº¯m Ä‘áº¥m, XÃ²e tay, 1, 2, 3, 4, Cá»­ chá»‰ báº­y báº¡).

---

## Transformer Overview
MÃ´ hÃ¬nh sá»­ dá»¥ng TransformerEncoder Ä‘á»ƒ xá»­ lÃ½ chuá»—i keypoints (21 Ä‘iá»ƒm trÃªn bÃ n tay, má»—i Ä‘iá»ƒm cÃ³ tá»a Ä‘á»™ (x, y, z)).

Pipeline xá»­ lÃ½: Keypoints Sequence â†’ Positional Encoding â†’ TransformerEncoder â†’ Pooling â†’ Classifier
MediaPipe phÃ¡t hiá»‡n bÃ n tay vÃ  trÃ­ch xuáº¥t keypoints (21Ã—3).
Chuáº©n hÃ³a dá»¯ liá»‡u keypoints (scale, translate).
Má»—i frame â†’ 1 vector (sequence length = 21, feature dim = 3).
Positional Encoding thÃªm thÃ´ng tin vá»‹ trÃ­.
TransformerEncoder há»c má»‘i quan há»‡ khÃ´ng gian giá»¯a cÃ¡c Ä‘iá»ƒm.
Pooling + Fully Connected Layer + Softmax â†’ dá»± Ä‘oÃ¡n nhÃ£n.

---

## ğŸ“¦ CÃ i Ä‘áº·t nhanh
Báº¡n cÃ³ thá»ƒ cÃ i theo hai cÃ¡ch:

**1. Sá»­ dá»¥ng `requirements.txt`**
```bash
pip install -r requirements.txt
```
**2. Sá»­ dá»¥ng trá»±c tiáº¿p**
```bash
pip install torch mediapipe opencv-python numpy scikit-learn
```
***3. Deploy streamlit***
```bash
streamlit run app.py
```
