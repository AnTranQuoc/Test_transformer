# Hand Gesture Recognition with TransformerEncoder

Real-time hand gesture recognition from keypoint data extracted using **MediaPipe**, powered by a **TransformerEncoder** model.  
The model can classify the following gestures:

- ğŸ‘Œ OK
- âœŠ Fist
- ğŸ– Open Hand
- â˜ One Finger
- âœŒ Two Fingers
- ğŸ¤Ÿ Three Fingers
- ğŸ–– Four Fingers
- ğŸ–• Offensive Gesture

---

## ğŸ¥ Video Demo
[![Watch the demo](demo_thumbnail.png)](demo_video.mp4)  
*Click the image above to watch the demo video.*

---

## ğŸ“Š Dataset
- **Source:** Keypoint data collected using **MediaPipe Hands**.
- **Format:** Each sample is a `(21, 3)` array containing `(x, y, z)` coordinates of 21 hand landmarks.
- **Preprocessing:**
  - Normalize position (translate wrist to origin).
  - Scale hand size to a consistent ratio.
- **Classes:** 8 gesture classes (OK, Fist, Open Hand, 1, 2, 3, 4, Offensive Gesture).

---

## ğŸ§  Transformer Overview
The model uses a **TransformerEncoder** to process the sequence of keypoints  
(21 points per hand, each with coordinates `(x, y, z)`).

**Processing Pipeline:**

Keypoints Sequence â†’ Positional Encoding â†’ TransformerEncoder â†’ Pooling â†’ Classifier

1. **MediaPipe** detects the hand and extracts `(21Ã—3)` keypoints.
2. Normalize the keypoints (scale, translate).
3. Each frame â†’ one vector (`sequence length = 21`, `feature dim = 3`).
4. Apply **Positional Encoding** to add spatial position information.
5. **TransformerEncoder** learns spatial relationships between keypoints.
6. **Pooling + Fully Connected Layer + Softmax** â†’ predict gesture label.

---

## ğŸ“¦ Quick Installation

You can install the dependencies in two ways:

**1ï¸âƒ£ Using `requirements.txt`:**
```bash
pip install -r requirements.txt
```
**2. Install directly**
```bash
pip install torch mediapipe opencv-python numpy scikit-learn
```
***3. Deploy with Streamlit***
```bash
streamlit run app.py
```
